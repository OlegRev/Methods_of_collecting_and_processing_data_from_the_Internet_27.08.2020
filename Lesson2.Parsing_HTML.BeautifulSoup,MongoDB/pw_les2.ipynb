{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задания\n",
    "    Необходимо собрать информацию о вакансиях на вводимую должность\n",
    "    (используем input или через аргументы) с сайтов Superjob и HH.\n",
    "    Приложение должно анализировать несколько страниц сайта\n",
    "    (также вводим через input или аргументы).\n",
    "    Получившийся список должен содержать в себе минимум:\n",
    "        Наименование вакансии.\n",
    "        Предлагаемую зарплату (отдельно минимальную и максимальную).\n",
    "        Ссылку на саму вакансию.\n",
    "        Сайт, откуда собрана вакансия.\n",
    "    По желанию можно добавить ещё параметры вакансии\n",
    "    (например, работодателя и расположение)\n",
    "    Структура должна быть одинаковая для вакансий с обоих сайтов.\n",
    "    Общий результат можно вывести с помощью dataFrame через pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restruct_compensation(compensation: str):\n",
    "    \"\"\"Функция обработки укзателя зарплаты для\n",
    "    разделения на минимальную, максимальную \n",
    "    и денежную единицу измерения \n",
    "    с использованием регулярных выражений\n",
    "    (функция содержит import re)\n",
    "\n",
    "    Args:\n",
    "        compensation (str):\n",
    "        тестировалось на выражениях:\n",
    "            ['30000-70000 руб.', 'до 96000 руб.', 'от 150000 руб.',\n",
    "             'от 150000 руб. до 200000 руб.', '200000-450000 KZT',\n",
    "             '2500-4000 USD', '3000000'\n",
    "            ]\n",
    "\n",
    "    Returns:\n",
    "        result (dict):\n",
    "            result.keys(): ['min_compensation',\n",
    "                            'max_compensation',\n",
    "                            'currency_compensation'\n",
    "                           ]\n",
    "    \"\"\"\n",
    "    import re\n",
    "    if compensation.isdigit():\n",
    "        result = {'min_compensation' : int(compensation),\n",
    "                  'max_compensation': int(compensation),\n",
    "                  'currency_compensation' : None\n",
    "                 }\n",
    "        return result\n",
    "\n",
    "    elif re.search(r'^до',compensation):\n",
    "        re_compensation = re.search(r'().*?(\\d{1,}).*?(\\w{3}).*?', compensation)\n",
    "    elif '-'in compensation or ('от' in compensation and 'до' in compensation):\n",
    "        re_compensation = re.search(r'.*?(\\d{1,}).*?(\\d{1,}).*?(\\w{3}).*?', compensation)\n",
    "    elif 'от' in compensation and 'до' not in compensation:\n",
    "        re_compensation = re.search(r'.*?(\\d{1,}).*?()(\\w{3}).*?', compensation)\n",
    "    \n",
    "    result = {'min_compensation' : re_compensation.group(1),\n",
    "              'max_compensation': re_compensation.group(2),\n",
    "              'currency_compensation' : re_compensation.group(3)\n",
    "             }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def parser_vacancy_item(required_vacancy:'bs4.element.Tag', website: str, parser_params: dict):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        required_vacancy (bs4.element.Tag): [description]\n",
    "        website (str): [https://spb.hh.ru or https://www.superjob.ru]\n",
    "        parser_params (dict): \n",
    "        [Описание для hh.ru]: {'vacancy_header_blok' : ['div', 'class', 'vacancy-serp-item__row_header'],\n",
    "                               'vacancy_info' : ['div', 'class', 'vacancy-serp-item__info'],\n",
    "                               'vacancy_sidebar_compensation' : ['div', 'class', 'vacancy-serp-item__sidebar'],\n",
    "                               'vacancy_link' : ['a', 'class', 'bloko-link'],\n",
    "                               'company_metainfo' : ['div', 'class', 'vacancy-serp-item__meta-info'],\n",
    "                               'company_link' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                               'company_name' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                               'company_location' : ['span', 'data-qa', 'vacancy-serp__vacancy-address']\n",
    "                              }  \n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    vacancy_data={}\n",
    "    vacancy_data['website'] = website\n",
    "    vacancy_header_blok = required_vacancy.find(parser_params['vacancy_header_blok'][0],\n",
    "                                                {parser_params['vacancy_header_blok'][1]:\n",
    "                                                 parser_params['vacancy_header_blok'][2]})\n",
    "    vacancy_info = vacancy_header_blok.find(parser_params['vacancy_info'][0],\n",
    "                                            {parser_params['vacancy_info'][1]:\n",
    "                                             parser_params['vacancy_info'][2]})\n",
    "    vacancy_sidebar_compensation = vacancy_header_blok.find(parser_params['vacancy_sidebar_compensation'][0],\n",
    "                                                            {parser_params['vacancy_sidebar_compensation'][1]:\n",
    "                                                             parser_params['vacancy_sidebar_compensation'][2]})\n",
    "    vacancy_name = vacancy_info.getText()\n",
    "    vacancy_link = vacancy_info.find(parser_params['vacancy_link'][0],\n",
    "                                     {parser_params['vacancy_link'][1]\n",
    "                                     : parser_params['vacancy_link'][2]}).get('href')\n",
    "    \n",
    "    vacancy_data['name'] = vacancy_name\n",
    "    \n",
    "    if website == 'hh.ru':\n",
    "        vacancy_data['link'] = vacancy_link\n",
    "        website = 'https://' + website\n",
    "        company_metainfo = required_vacancy.find_all(parser_params['company_metainfo'][0],\n",
    "                                                     {parser_params['company_metainfo'][1]\n",
    "                                                     :parser_params['company_metainfo'][2]})\n",
    "    elif website == 'superjob.ru':\n",
    "        website = 'https://www.' + website\n",
    "        vacancy_data['link'] = website + vacancy_link\n",
    "        company_metainfo = required_vacancy.find(parser_params['company_metainfo'][0],\n",
    "                                                 {parser_params['company_metainfo'][1]\n",
    "                                                 :parser_params['company_metainfo'][2]})\n",
    "        company_metainfo = company_metainfo.find_all(parser_params['company_metainfo'][3],\n",
    "                                                     {parser_params['company_metainfo'][4]\n",
    "                                                     :parser_params['company_metainfo'][5]})\n",
    "        \n",
    "    try:\n",
    "        company_link = company_metainfo[0].find(parser_params['company_link'][0],\n",
    "                                                {parser_params['company_link'][1]\n",
    "                                                : parser_params['company_link'][2]}).get('href')\n",
    "        vacancy_data['company_link'] = website + company_link \n",
    "        \n",
    "    except:\n",
    "        vacancy_data['company_link'] = None        \n",
    "    try: \n",
    "        company_name = company_metainfo[0].find(parser_params['company_name'][0],\n",
    "                                                {parser_params['company_name'][1]\n",
    "                                                : parser_params['company_name'][2]}).getText()\n",
    "        vacancy_data['company_name'] = company_name\n",
    "    except:\n",
    "        vacancy_data['company_name'] = None\n",
    "    try:\n",
    "        company_location = company_metainfo[1].find(parser_params['company_location'][0],\n",
    "                                                    {parser_params['company_location'][1]\n",
    "                                                    : parser_params['company_location'][2]}).getText()\n",
    "        vacancy_data['company_location'] = company_location\n",
    "    except:\n",
    "        vacancy_data['company_location'] = None\n",
    "    try:\n",
    "        vacancy_compensation = vacancy_sidebar_compensation.getText()\n",
    "        vacancy_compensation = vacancy_compensation.replace('\\xa0', '')\n",
    "        vacancy_compensation = restruct_compensation(vacancy_compensation)\n",
    "        vacancy_data['min_compensation'] = vacancy_compensation['min_compensation']\n",
    "        vacancy_data['max_compensation'] = vacancy_compensation['max_compensation']\n",
    "        vacancy_data['currency_compensation'] = vacancy_compensation['currency_compensation']\n",
    "    except:\n",
    "        vacancy_data['min_compensation'] = None\n",
    "        vacancy_data['max_compensation'] = None\n",
    "        vacancy_data['currency_compensation'] = None\n",
    "            \n",
    "    return vacancy_data\n",
    "\n",
    "\n",
    "def get_pars_response(website: str, required_vacancy: str, headers: dict, num_area: int = 0, page:str = ''):\n",
    "    if website == 'hh.ru':\n",
    "        main_link = 'https://hh.ru'\n",
    "        second_link = '/search/vacancy'\n",
    "        params_link =  {'fromSearchLine': 'true',\n",
    "                        'L_is_autosearch':'false',\n",
    "                        'area': num_area,\n",
    "                        'enable_snippets':'true',\n",
    "                        'salary': '',\n",
    "                        'st':'searchVacancy',\n",
    "                        'text': required_vacancy,\n",
    "                        'page': page}\n",
    "    elif website == 'superjob.ru':\n",
    "        main_link = 'https://www.superjob.ru'\n",
    "        second_link ='/vacancy/search/'\n",
    "        params_link = {'keywords': required_vacancy,\n",
    "                       'noGeo': '1',\n",
    "                       'page': page\n",
    "                      }\n",
    "    \n",
    "    full_link = main_link + second_link\n",
    "    return requests.get(full_link, params=params_link, headers=headers)\n",
    "    \n",
    "\n",
    "def get_vacancies(website: str, required_vacancy: str, headers: dict, parser_params: dict, num_area: int = 0):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        website (str): 'hh.ru', 'superjob.ru'\n",
    "        required_vacancy (str): [description]\n",
    "        num_area (int, optional): [description]. Defaults to 0.\n",
    "        parser_params (dict) = {'pages_blok': ['div', 'data-qa', 'pager-block'],\n",
    "                                'pages_list': ['a', 'class', 'bloko-button'],\n",
    "                                'vacancies_serp': ['div', 'class', 'vacancy-serp', 'vacancy-serp-item'],\n",
    "                                'vacancy_header_blok' : ['div', 'class', 'vacancy-serp-item__row_header'],\n",
    "                                'vacancy_info' : ['div', 'class', 'vacancy-serp-item__info'],\n",
    "                                'vacancy_sidebar_compensation' : ['div', 'class', 'vacancy-serp-item__sidebar'],\n",
    "                                'vacancy_link' : ['a', 'class', 'bloko-link'],\n",
    "                                'company_metainfo' : ['div', 'class', 'vacancy-serp-item__meta-info'],\n",
    "                                'company_link' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                                'company_name' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                                'company_location' : ['span', 'data-qa', 'vacancy-serp__vacancy-address']\n",
    "                               } - for hh.ru\n",
    "        parser_params (dict) = {'vacancy_header_blok' : ['div', 'class', 'jNMYr GPKTZ _1tH7S'],\n",
    "                                'vacancy_info' : ['div', 'class', '_3mfro PlM3e _2JVkc _3LJqf'],\n",
    "                                'vacancy_sidebar_compensation' : ['span', 'class', '_1OuF_ _1qw9T f-test-text-company-item-salary'],\n",
    "                                'vacancy_link' : ['a', 'target', '_blank'],\n",
    "                                'company_metainfo' : ['div', 'class', '_3_eyK _3P0J7 _9_FPy', 'div', 'class', '_2g1F-'],\n",
    "                                'company_link' : ['a', 'target', '_self'],\n",
    "                                'company_name' : ['a', 'target', '_self'],\n",
    "                                'company_location' : ['span', 'class', '_3mfro f-test-text-company-item-location _9fXTd _2JVkc _2VHxz'],\n",
    "                                'pages_blok': ['div', 'class', '_3zucV L1p51 undefined _1Fty7 _2tD21 _3SGgo'],\n",
    "                                'pages_list': ['a', 'target', '_self'],\n",
    "                                'vacanies_serp': ['div', 'class', '_1ID8B', 'Fo44F QiY08 LvoDO']\n",
    "                               } - for superjob.ru\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    vacancies_data = []\n",
    "    response_page = get_pars_response(website , required_vacancy , headers, num_area = num_area)\n",
    "    if response_page.ok:\n",
    "        soup = bs(response_page.text,'html.parser')\n",
    "        try:\n",
    "            pages_blok = soup.find(parser_params['pages_blok'][0],\n",
    "                                   {parser_params['pages_blok'][1]\n",
    "                                   : parser_params['pages_blok'][2]})\n",
    "            pages_list = pages_blok.find_all(parser_params['pages_list'][0],\n",
    "                                             {parser_params['pages_list'][1]\n",
    "                                             : parser_params['pages_list'][2]})\n",
    "            last_page_number = int(pages_list[-2].getText())\n",
    "        except:\n",
    "            last_page_number = 1\n",
    "        \n",
    "\n",
    "    for page in range(last_page_number):\n",
    "        response_page = get_pars_response(website , required_vacancy , headers, num_area = num_area, page=page)\n",
    "        if response_page.ok:\n",
    "            soup = bs(response_page.text,'html.parser')\n",
    "    \n",
    "            vacancies_serp = soup.find(parser_params['vacancies_serp'][0],\n",
    "                                       {parser_params['vacancies_serp'][1]\n",
    "                                       : parser_params['vacancies_serp'][2]})\n",
    "            vacancies_serp = vacancies_serp.find_all(parser_params['vacancies_serp'][0],\n",
    "                                                     {parser_params['vacancies_serp'][1]\n",
    "                                                     : parser_params['vacancies_serp'][3]})\n",
    "            for vacancy in vacancies_serp:\n",
    "                vacancies_data.append(parser_vacancy_item(vacancy,parser_params=parser_params, website=website))\n",
    "    \n",
    "    return vacancies_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vacancies_list(website_list: list ,\n",
    "                       required_vacancy: str,\n",
    "                       headers: dict,\n",
    "                       num_area: int = 0):\n",
    "    \"\"\"Функция преобразования в датафрейм полученых вакансий  с сайтов:\n",
    "        'hh.ru', 'superjob.ru'\n",
    "\n",
    "    Args:\n",
    "        website_list (list): ['hh.ru', 'superjob.ru']\n",
    "        required_vacancy (str): [description]\n",
    "        headers (dict): [description]\n",
    "        num_area (int, optional): [description]. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        vacancies_data (list): [description]\n",
    "    \"\"\"\n",
    "   \n",
    "    vacancies_data = []\n",
    "    hh_parser_params = {'pages_blok': ['div', 'data-qa', 'pager-block'],\n",
    "                        'pages_list': ['a', 'class', 'bloko-button'],\n",
    "                        'vacancies_serp': ['div', 'class', 'vacancy-serp', 'vacancy-serp-item'],\n",
    "                        'vacancy_header_blok' : ['div', 'class', 'vacancy-serp-item__row_header'],\n",
    "                        'vacancy_info' : ['div', 'class', 'vacancy-serp-item__info'],\n",
    "                        'vacancy_sidebar_compensation' : ['div', 'class', 'vacancy-serp-item__sidebar'],\n",
    "                        'vacancy_link' : ['a', 'class', 'bloko-link'],\n",
    "                        'company_metainfo' : ['div', 'class', 'vacancy-serp-item__meta-info'],\n",
    "                        'company_link' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                        'company_name' : ['a', 'data-qa', 'vacancy-serp__vacancy-employer'],\n",
    "                        'company_location' : ['span', 'data-qa', 'vacancy-serp__vacancy-address']\n",
    "                       } \n",
    "    sj_parser_params = {'company_location' : ['span', 'class', '_3mfro f-test-text-company-item-location _9fXTd _2JVkc _2VHxz'],\n",
    "                        'pages_blok': ['div', 'class', '_3zucV L1p51 undefined _1Fty7 _2tD21 _3SGgo'],\n",
    "                        'pages_list': ['a', 'target', '_self'],\n",
    "                        'vacancies_serp': ['div', 'class', '_1ID8B', 'Fo44F QiY08 LvoDO'],\n",
    "                        'vacancy_header_blok' : ['div', 'class', 'jNMYr GPKTZ _1tH7S'],\n",
    "                        'vacancy_info' : ['div', 'class', '_3mfro PlM3e _2JVkc _3LJqf'],\n",
    "                        'vacancy_sidebar_compensation' : ['span', 'class', '_1OuF_ _1qw9T f-test-text-company-item-salary'],\n",
    "                        'vacancy_link' : ['a', 'target', '_blank'],\n",
    "                        'company_metainfo' : ['div', 'class', '_3_eyK _3P0J7 _9_FPy', 'div', 'class', '_2g1F-'],\n",
    "                        'company_link' : ['a', 'target', '_self'],\n",
    "                        'company_name' : ['a', 'target', '_self']\n",
    "                       }\n",
    "    for website in website_list:\n",
    "        if website == 'hh.ru':\n",
    "            parser_params = hh_parser_params\n",
    "        elif  website == 'superjob.ru':\n",
    "            parser_params = sj_parser_params\n",
    "        vacancies_data.extend(get_vacancies(website, required_vacancy, headers, parser_params, num_area=num_area))\n",
    "    return vacancies_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vacancy = 'Data Scientist'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) '\n",
    "           'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36'\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vacancy = 'Data Scientist'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) '\n",
    "           'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36'\n",
    "          }\n",
    "vacancies = get_vacancies_list(website_list=['hh.ru', 'superjob.ru'],\n",
    "                              required_vacancy=required_vacancy,\n",
    "                              headers=headers)\n",
    "df = pd.DataFrame(vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>company_link</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_location</th>\n",
       "      <th>min_compensation</th>\n",
       "      <th>max_compensation</th>\n",
       "      <th>currency_compensation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hh.ru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://spb.hh.ru/vacancy/39084549</td>\n",
       "      <td>https://hh.ru/employer/4295296</td>\n",
       "      <td>ООО Софтвайс</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>150000</td>\n",
       "      <td>200000</td>\n",
       "      <td>руб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hh.ru</td>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>https://spb.hh.ru/vacancy/39110818</td>\n",
       "      <td>https://hh.ru/employer/1787419</td>\n",
       "      <td>Spark Equation</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>110000</td>\n",
       "      <td>180000</td>\n",
       "      <td>руб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hh.ru</td>\n",
       "      <td>Junior/Middle ML Engineer/ Data Scientist (New...</td>\n",
       "      <td>https://spb.hh.ru/vacancy/38523760</td>\n",
       "      <td>https://hh.ru/employer/789662</td>\n",
       "      <td>SEMrush</td>\n",
       "      <td>Санкт-Петербург, Московские ворота</td>\n",
       "      <td>140000</td>\n",
       "      <td></td>\n",
       "      <td>руб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hh.ru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://spb.hh.ru/vacancy/38238647</td>\n",
       "      <td>https://hh.ru/employer/4327016</td>\n",
       "      <td>ООО Цифровое проектирование</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>110000</td>\n",
       "      <td></td>\n",
       "      <td>руб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hh.ru</td>\n",
       "      <td>Математик-аналитик (data scientist / data anal...</td>\n",
       "      <td>https://spb.hh.ru/vacancy/38349035</td>\n",
       "      <td>https://hh.ru/employer/2954482</td>\n",
       "      <td>ООО ННФормат</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>85000</td>\n",
       "      <td></td>\n",
       "      <td>руб</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  website                                               name  \\\n",
       "0   hh.ru                                     Data Scientist   \n",
       "1   hh.ru                            Data Scientist (Remote)   \n",
       "2   hh.ru  Junior/Middle ML Engineer/ Data Scientist (New...   \n",
       "3   hh.ru                                     Data Scientist   \n",
       "4   hh.ru  Математик-аналитик (data scientist / data anal...   \n",
       "\n",
       "                                 link                    company_link  \\\n",
       "0  https://spb.hh.ru/vacancy/39084549  https://hh.ru/employer/4295296   \n",
       "1  https://spb.hh.ru/vacancy/39110818  https://hh.ru/employer/1787419   \n",
       "2  https://spb.hh.ru/vacancy/38523760   https://hh.ru/employer/789662   \n",
       "3  https://spb.hh.ru/vacancy/38238647  https://hh.ru/employer/4327016   \n",
       "4  https://spb.hh.ru/vacancy/38349035  https://hh.ru/employer/2954482   \n",
       "\n",
       "                  company_name                    company_location  \\\n",
       "0                 ООО Софтвайс                     Санкт-Петербург   \n",
       "1               Spark Equation                     Санкт-Петербург   \n",
       "2                      SEMrush  Санкт-Петербург, Московские ворота   \n",
       "3  ООО Цифровое проектирование                     Санкт-Петербург   \n",
       "4                 ООО ННФормат                     Санкт-Петербург   \n",
       "\n",
       "  min_compensation max_compensation currency_compensation  \n",
       "0           150000           200000                   руб  \n",
       "1           110000           180000                   руб  \n",
       "2           140000                                    руб  \n",
       "3           110000                                    руб  \n",
       "4            85000                                    руб  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spb.hh.ru/vacancy/33608231'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.link[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'website': 'hh.ru',\n",
       "  'name': 'Data Scientist',\n",
       "  'link': 'https://spb.hh.ru/vacancy/39084549',\n",
       "  'company_link': 'https://hh.ru/employer/4295296',\n",
       "  'company_name': 'ООО Софтвайс',\n",
       "  'company_location': 'Санкт-Петербург',\n",
       "  'min_compensation': '150000',\n",
       "  'max_compensation': '200000',\n",
       "  'currency_compensation': 'руб'},\n",
       " {'website': 'hh.ru',\n",
       "  'name': 'Data Scientist (Remote)',\n",
       "  'link': 'https://spb.hh.ru/vacancy/39110818',\n",
       "  'company_link': 'https://hh.ru/employer/1787419',\n",
       "  'company_name': ' Spark Equation',\n",
       "  'company_location': 'Санкт-Петербург',\n",
       "  'min_compensation': '110000',\n",
       "  'max_compensation': '180000',\n",
       "  'currency_compensation': 'руб'},\n",
       " {'website': 'hh.ru',\n",
       "  'name': 'Junior/Middle ML Engineer/ Data Scientist (New Team)',\n",
       "  'link': 'https://spb.hh.ru/vacancy/38523760',\n",
       "  'company_link': 'https://hh.ru/employer/789662',\n",
       "  'company_name': ' SEMrush',\n",
       "  'company_location': 'Санкт-Петербург, Московские ворота',\n",
       "  'min_compensation': '140000',\n",
       "  'max_compensation': '',\n",
       "  'currency_compensation': 'руб'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancies[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
